import warnings
import os
import re
from collections import Counter
from googletrans import Translator
from pydub import AudioSegment
from pydub.silence import detect_nonsilent
import spacy
import whisper
from moviepy import VideoFileClip
from transformers import pipeline, BartTokenizer

# Configuration
warnings.filterwarnings("ignore")
TEMP_AUDIO = "temp_audio.wav"
CHUNK_FOLDER = "audio_chunks"
WHISPER_MODEL = "small"  # tiny/base/small/medium/large

class FootballMatchAnalyzer:
    def __init__(self):
        """Initialise tous les mod√®les et outils"""
        print("‚öôÔ∏è Chargement des mod√®les...")
        self.whisper_model = whisper.load_model(WHISPER_MODEL)
        self.nlp = spacy.load("en_core_web_sm")
        self.summarizer = pipeline(
            "summarization",
            model="facebook/bart-large-cnn",
            tokenizer="facebook/bart-large-cnn"
        )
        self.tokenizer = BartTokenizer.from_pretrained("facebook/bart-large-cnn")
        self.translator = Translator()
        os.makedirs(CHUNK_FOLDER, exist_ok=True)

    def extract_audio(self, video_path):
        """Extrait l'audio de la vid√©o"""
        print(f"üîä Extraction audio depuis {video_path}...")
        try:
            with VideoFileClip(video_path) as video:
                video.audio.write_audiofile(
                    TEMP_AUDIO,
                    codec='pcm_s16le',
                    fps=16000,
                )
            return TEMP_AUDIO
        except Exception as e:
            raise RuntimeError(f"√âchec extraction audio: {str(e)}")

    def split_audio(self, audio_path):
        """D√©coupe l'audio en segments intelligents"""
        print("‚úÇÔ∏è D√©coupage audio...")
        try:
            audio = AudioSegment.from_wav(audio_path)
            non_silent_ranges = detect_nonsilent(
                audio,
                min_silence_len=1000,
                silence_thresh=-40
            )
            
            chunks = []
            for i, (start, end) in enumerate(non_silent_ranges):
                chunk_path = os.path.join(CHUNK_FOLDER, f"chunk_{i}.wav")
                audio[start:end].export(chunk_path, format="wav")
                chunks.append(chunk_path)
                
            return chunks if chunks else [audio_path]
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur d√©coupage: {str(e)}")
            return [audio_path]

    def transcribe_audio(self, chunk_path):
        """Transcrit un segment audio en texte"""
        try:
            result = self.whisper_model.transcribe(
                chunk_path,
                language="en",
                initial_prompt=(
                    "Football commentary with players like Salah, Kane. "
                    "Focus on goals, cards, substitutions. "
                    "Ignore crowd noise."
                ),
                temperature=0.2
            )
            return result["text"].strip()
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur transcription: {str(e)}")
            return ""

    def analyze_text(self, text):
        """Analyse le texte pour d√©tecter les √©v√©nements"""
        print("‚öΩ Analyse des √©v√©nements...")
        doc = self.nlp(text)
        events = []
        
        # D√©tection des joueurs
        players = set()
        for ent in doc.ents:
            if (ent.label_ == "PERSON" and ent.text.istitle() 
                and len(ent.text.split()) <= 3):
                players.add(ent.text)
        
        # D√©tection des actions
        action_patterns = {
            'goal': r'\b(goal|scored|netted)\b',
            'card': r'\b(yellow card|red card|booked)\b',
            'substitution': r'\b(sub|substitution|replaced)\b',
            'foul': r'\b(foul|handball|penalty)\b'
        }
        
        for sent in doc.sents:
            for action, pattern in action_patterns.items():
                if re.search(pattern, sent.text, re.IGNORECASE):
                    for player in players:
                        if player in sent.text:
                            events.append({
                                'player': player,
                                'action': action,
                                'details': sent.text.strip()
                            })
        
        # √âlimination des doublons
        unique_events = []
        seen = set()
        for ev in events:
            key = (ev['player'], ev['action'], ev['details'][:50])
            if key not in seen:
                seen.add(key)
                unique_events.append(ev)
                
        return unique_events

    def generate_summary(self, text):
        """G√©n√®re un r√©sum√© structur√©"""
        print("üìù Cr√©ation du r√©sum√©...")
        try:
            # D√©coupage en chunks
            chunks = self._chunk_text(text)
            stage1_summaries = []
            
            for chunk in chunks:
                summary = self.summarizer(
                    chunk,
                    max_length=150,
                    min_length=30,
                    do_sample=False
                )
                stage1_summaries.append(summary[0]['summary_text'])
            
            # R√©sum√© final
            final_summary = self.summarizer(
                " ".join(stage1_summaries),
                max_length=300,
                min_length=100,
                do_sample=False
            )
            
            return self._format_bullet_points(final_summary[0]['summary_text'])
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur r√©sum√©: {str(e)}")
            return self._format_bullet_points(text[:500])

    def translate_summary(self, summary):
        """Traduit le r√©sum√© en fran√ßais"""
        print("üåç Traduction...")
        try:
            # Traduction du texte sans puces
            clean_text = ' '.join([line[2:] for line in summary.split('\n') if line])
            translated = self.translator.translate(
                clean_text,
                src='en',
                dest='fr',
                timeout=10
            ).text
            
            # Remise en forme
            return self._format_bullet_points(translated)
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur traduction: {str(e)}")
            return self._format_fallback_translation(summary)

    def _chunk_text(self, text, max_tokens=1000):
        """D√©coupe le texte en morceaux"""
        paragraphs = [p for p in text.split('\n') if p.strip()]
        chunks = []
        current_chunk = []
        current_length = 0
        
        for para in paragraphs:
            para_len = len(self.tokenizer.tokenize(para))
            if current_length + para_len > max_tokens:
                chunks.append("\n".join(current_chunk))
                current_chunk = []
                current_length = 0
            current_chunk.append(para)
            current_length += para_len
            
        if current_chunk:
            chunks.append("\n".join(current_chunk))
            
        return chunks

    def _format_bullet_points(self, text):
        """Formate en liste √† puces"""
        sentences = [
            f"- {s.strip().capitalize()}" 
            for s in re.split(r'[.!?]', text) 
            if s.strip()
        ]
        return "\n".join(sentences[:15])

    def _format_fallback_translation(self, text):
        """Formatage de secours"""
        return text.replace("goal", "but").replace("penalty", "p√©nalty")

    def cleanup(self):
        """Nettoyage des fichiers temporaires"""
        try:
            if os.path.exists(TEMP_AUDIO):
                os.remove(TEMP_AUDIO)
            if os.path.exists(CHUNK_FOLDER):
                for f in os.listdir(CHUNK_FOLDER):
                    os.remove(os.path.join(CHUNK_FOLDER, f))
                os.rmdir(CHUNK_FOLDER)
        except:
            pass

    def analyze_video(self, video_path):
        """Pipeline complet d'analyse"""
        try:
            # 1. Extraction audio
            audio_file = self.extract_audio(video_path)
            
            # 2. D√©coupage audio
            chunks = self.split_audio(audio_file)
            print(f"üîà {len(chunks)} segments cr√©√©s")
            
            # 3. Transcription
            print("üìú Transcription...")
            transcripts = [self.transcribe_audio(chunk) for chunk in chunks]
            full_text = "\n".join([t for t in transcripts if t.strip()])
            
            if not full_text.strip():
                raise ValueError("Aucun contenu transcrit")
            
            # 4. Analyse
            events = self.analyze_text(full_text)
            summary = self.generate_summary(full_text)
            french_summary = self.translate_summary(summary)
            
            return {
                'transcription': full_text,
                'events': events,
                'english_summary': summary,
                'french_summary': french_summary
            }
            
        finally:
            self.cleanup()

# Exemple d'utilisation
if __name__ == "__main__":
    analyzer = FootballMatchAnalyzer()
    results = analyzer.analyze_video("match.mp4")
    
    print("\n" + "="*50)
    print("üìã RESULTATS COMPLETS")
    print("="*50)
    
    print("\n‚öΩ √âV√âNEMENTS CL√âS:")
    for event in results['events'][:10]:
        print(f"- {event['player']}: {event['action']}")
    
    print("\nüá¨üáß R√âSUM√â ANGLAIS:")
    print(results['english_summary'])
    
    print("\nüá´üá∑ R√âSUM√â FRAN√áAIS:")
    print(results['french_summary'])
    
    print("\n‚úÖ Analyse termin√©e!")